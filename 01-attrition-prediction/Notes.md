# üìä Understanding the Model Output: Employee Attrition Prediction

After training your machine learning model in the `attrition_model.ipynb` notebook, you see output like this:

```
              precision    recall  f1-score   support

           0       0.88      0.95      0.91       246
           1       0.75      0.53      0.62        54

    accuracy                           0.86       300
   macro avg       0.82      0.74      0.77       300
weighted avg       0.86      0.86      0.85       300
```

## üîç What It Means

### Class Labels

* `0`: Employee **did not leave** the company
* `1`: Employee **did leave** the company (this is what you're trying to predict)

### Metrics Explained

| Metric        | What it tells you                                                            |
| ------------- | ---------------------------------------------------------------------------- |
| **Precision** | Of the people the model predicted would leave, how many actually did?        |
| **Recall**    | Of all the people who actually left, how many did the model catch?           |
| **F1-score**  | A balance between precision and recall (higher = better overall performance) |
| **Support**   | How many real examples there were of that class in the test data             |

### Accuracy

* `accuracy = 0.86` means the model correctly predicted attrition (yes or no) for **86% of test employees**.

### Macro vs Weighted Averages

* **Macro avg**: Average performance across both classes, treating them equally.
* **Weighted avg**: Average weighted by how many examples are in each class (e.g. more employees stayed than left).

## üß† Model Behavior

* The model performs **very well on people who stay** (`0`) with high precision/recall.
* For people who **left** (`1`), the recall is lower (53%), meaning it misses some true leavers.

## üîÅ How to Improve It

* Balance the dataset (e.g. oversample leavers)
* Tune the model (e.g. adjust RandomForest parameters)
* Try other algorithms like logistic regression, XGBoost, or LightGBM
* Add more predictive features (like performance scores, recent promotions, etc.)

## üìå Conclusion

This output is your **model performance summary** ‚Äî it tells you how well your AI predicts attrition. To truly make it useful, aim to increase recall for leavers and test on new or changing data.

---

Need a visual explanation? Consider adding a **confusion matrix** chart to your notebook.
